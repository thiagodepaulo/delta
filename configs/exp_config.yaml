
trainer:
  max_epochs: 500
  batch_size: 512 #32
  optimizer: Adam
  learning_rate: 2e-3  ## caimira good 1e-3 0.002
  num_workers: 2
  betas: [0.9, 0.999]
  scheduler:  none # cosine 

  #cosine schedule
  warmup_steps: -1  # if -1, will use 5% of total steps
  min_lr: 1e-7  ## caimira good 1e-7

  

caimira:
  n_dim: 5
  n_users: 1500
  n_dim_user_embed: 1536  
  n_dim_item_embed: 1536
  lambda_s : 1e-6
  lambda_d : 1e-6

model1:
  n_dim: 5
  n_dim_prompt_embed: 1536
  n_dim_answer_embed: 1536
  n_dim_user_embed: 1536
  n_dim_user_embed_2: 10
  n_dim_user_features: 45
  n_users: 1500
  lambda_x: 1e-6
  lambda_y: 1e-6
  lambda_r: 1e-6
  lambda_u: 1e-6
  has_user_features: false

model2:
  n_dim: 5
  n_dim_prompt_embed: 1536
  n_dim_answer_embed: 1536
  n_dim_user_embed: 1536
  n_dim_user_embed_2: 16
  n_dim_user_features: 45
  n_users: 1500
  lambda_x: 1e-5
  lambda_y: 1e-5
  lambda_r: 1e-5
  lambda_u: 1e-5
  has_user_features: false

ntm:  
  words_emb_dim: 300
  n_topics: 6
  n_labels: 1
  n_prior_covars: -1
  n_topic_covars: -1
  classifier_layers: 100
  use_interactions: false
  l1_beta_reg: 0.0
  l1_beta_c_reg: 0.0
  l1_beta_ci_reg: 0.0
  l2_prior_reg: 0.0
  classify_from_covars: True  
  user_covars: true